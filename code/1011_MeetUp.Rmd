---
title: "MeetUp Data Exploration"
author: "Myeong Lee"
date: "10/11/2016"
output: html_document
---


```{r, echo=FALSE}
library(maps)
library(geosphere)
library(readr)
library(dplyr)
library(magrittr)
library(lubridate)
library(rgdal)
library(raster)
library(rgeos)
require(ggplot2)
library(cwhmisc)
library(utils)
library(rpart)
library(stringr)
library(hydroGOF)
library(fields)
library(MASS)
library(e1071)
library(raster)
library(reshape2)
library(igraph)
library(Hmisc)
library(randomForest)
library(caret)
library(leaflet)
library(RColorBrewer)
library(classInt)
library(maptools)
library(googleVis)
library(ggmap)
library(rvest)
library(tm)
library(topicmodels)
library(ldatuning)
```


# Group Data Loading
```{r}
setwd("/Users/myeong/git/meetup/data/cleaned_up_John/")

groups = read_delim("group_results.csv", delim = ",",col_names = TRUE ) 
groups$description <- sapply(groups$description, function(x) gsub("<.*?>", "", x))

# data_groups <- groups[grep("data", groups$tags), ]
data_groups <- groups
data_groups$date <- paste(data_groups$year,data_groups$month,data_groups$day,sep="")
```


# Data Reshaping
```{r}

data_reshaped <- reshape2::melt(data_groups, id=c("group_id","date"))
data_reshaped <- data_reshaped[order(data_reshaped$group_id),] 
data_reshaped <- data_reshaped[data_reshaped$variable == "tags",] 

data_reshaped2 <- melt(data_groups, id=c("group_id","date"))
data_reshaped2 <- data_reshaped2[order(data_reshaped2$group_id),] 
data_reshaped2 <- data_reshaped2[data_reshaped2$variable == "description",] 

library(reshape)
final <- cast(data_reshaped, group_id~date, function(x) length(unlist(strsplit(x, ","))), value="tags")
# final <- cast(data_reshaped, group_id~date, value="tags")

# counting the number of changes
for (i in 1:nrow(final)){
  nums <- unique(unlist(final[i, 2:13]))
  k <- length(nums)
  
  if (0 %in% nums){
    k <- k-1
  }  
  
  final$unique[i] <- k 
}

summary(final$unique)
hist(final$unique)
table(final$unique[final$unique != 0])

#counting the number of additions
for (i in 1:nrow(final)){
  prev = 0
  add = 0
  sub = 0
  
  seq <- unlist(final[i, 2:13])
  
  for (j in 1:length(seq)){
    if (prev == seq[j] || j == 1 ) {
      prev <- seq[j]
      next
    } else if (prev < seq[j] ){
      add <- add + 1
    } else {
      sub <- sub + 1
    }
    prev <- seq[j]
  }
  
  final$add[i] <- add
  final$sub[i] <- sub
}

summary(final$add)
table(final$add)
hist(final$add)

summary(final$sub)
table(final$sub)
hist(final$sub)


myReader <- readTabular(mapping=list(content="description", id="GID"))
tm <- VCorpus(DataframeSource(data_groups), readerControl=list(reader=myReader))
tm <-tm_map(tm,content_transformer(tolower))
toSpace <- content_transformer(function(x, pattern) { return (gsub(pattern, " ", x))})
tm <- tm_map(tm, toSpace, "-")
tm <- tm_map(tm, toSpace, "'")
tm <- tm_map(tm, removePunctuation)
#Strip digits
tm <- tm_map(tm, removeNumbers)
#remove stopwords
tm <- tm_map(tm, removeWords, stopwords("english"))
#remove whitespace
tm <- tm_map(tm, stripWhitespace)

#custom stopwords
myStopwords <- c("nbsp", "amp", "meetup", "http", "can", "get", "will", "join", "like", "group", "event", "events", "people", "new")
tm <- tm_map(tm, removeWords, myStopwords)

#writeLines(as.character(tm[[30]]))
dtm <- DocumentTermMatrix(tm)
dtm <- removeSparseTerms(dtm, sparse=0.98)

rm(groups)
rm(tm)


```

```{r}

burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE

k <- 22 # number of topic categories on MeetUp.com

rowTotals <- apply(dtm , 1, sum)
dtm   <- dtm[rowTotals> 0, ] 

# dtm_short <- dtm[1:10,]
# 
# result <- FindTopicsNumber(
#   dtm_short,
#   topics = seq(from = 3, to = 10, by = 1),
#   metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
#   method = "Gibbs",
#   control = list(100),
#   mc.cores = 2L,
#   verbose = TRUE
# )
# lda_out <- LDA(dtm, k, method="Gibbs", control=list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))

lda_out <- LDA(dtm, 25)
lda_out.topics <- as.matrix(topics(lda_out))
write.csv(lda_out.topics,file=paste("LDAstop",k,"DocsToTopics.csv"))

#top 6 terms in each topic
lda_out.terms <- as.matrix(terms(lda_out,10))
write.csv(lda_out.terms,file=paste("LDAstop",k,"TopicToTerms.csv"))

#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(lda_out@gamma)
write.csv(topicProbabilities,file=paste("LDAstop",k,"TopicProb.csv"))

```

```{r}
data_reshaped <- melt(data_groups, id=c("group_id","date"))
data_reshaped <- data_reshaped[order(data_reshaped$group_id),] 
data_reshaped <- data_reshaped[data_reshaped$variable == "GID",] 

lda_out.topics <- as.data.frame(lda_out.topics)
lda_out.topics$GID <- rownames(lda_out.topics)
data_reshaped = data_reshaped %>% left_join(lda_out.topics, by = c("value" = "GID"))

data_reshaped$value <- data_reshaped$V1
library(reshape)
final <- cast(data_reshaped, group_id~date, value="V1")

for (i in 1:nrow(final)){
  nums <- unique(unlist(final[i, 2:13]))
  k <- length(nums)
  
  if (NA %in% nums){
    k <- k-1
  }  
  
  final$unique[i] <- k 
}

#Group description's topic modeling (how many unique topics are available?)
summary(final$unique)
hist(final$unique[final$unique != 0])
table(final$unique[final$unique != 0])
```


# Event
```{r}
events = read_delim("events_results.csv", delim = ",",col_names = TRUE ) 

events$description <- sapply(events$description, function(x) gsub("<.*?>", "", x))  
events$date <- paste(events$year,events$month,events$day,sep="")
events$date <- as.Date(events$date, "%d %B %Y");

myReader <- readTabular(mapping=list(content="description", id="EID"))
tm <- VCorpus(DataframeSource(events), readerControl=list(reader=myReader))
tm <-tm_map(tm,content_transformer(tolower))
toSpace <- content_transformer(function(x, pattern) { return (gsub(pattern, " ", x))})
tm <- tm_map(tm, toSpace, "-")
tm <- tm_map(tm, toSpace, "'")
tm <- tm_map(tm, removePunctuation)
#Strip digits
tm <- tm_map(tm, removeNumbers)
#remove stopwords
tm <- tm_map(tm, removeWords, stopwords("english"))
#remove whitespace
tm <- tm_map(tm, stripWhitespace)

#custom stopwords
myStopwords <- c("nbsp", "amp", "meetup", "http", "can", "get", "will", "join", "like", "group", "event", "events", "people", "new")
tm <- tm_map(tm, removeWords, myStopwords)

#writeLines(as.character(tm[[30]]))
dtm <- DocumentTermMatrix(tm)
dtm <- removeSparseTerms(dtm, sparse=0.98)

k <- 22 # number of topic categories on MeetUp.com

rowTotals <- apply(dtm , 1, sum)
dtm   <- dtm[rowTotals> 0, ] 

# lda_out <- LDA(dtm, k, method="Gibbs", control=list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))

lda_out <- LDA(dtm, k)
lda_out.topics <- as.matrix(topics(lda_out))
write.csv(lda_out.topics,file=paste("event",k,"DocsToTopics.csv"))

#top 6 terms in each topic
lda_out.terms <- as.matrix(terms(lda_out,10))
write.csv(lda_out.terms,file=paste("event",k,"TopicToTerms.csv"))

#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(lda_out@gamma)
write.csv(topicProbabilities,file=paste("event",k,"TopicProb.csv"))



## Connecting Topics to Event Data

events = read_delim("events_results.csv", delim = ",",col_names = TRUE ) 
events$description <- sapply(events$description, function(x) gsub("<.*?>", "", x))  
events$date <- as.Date(events$date, "%d %B %Y");
lda_out.topics = read_delim("event 22 DocsToTopics.csv", delim = ",",col_names = TRUE ) 


data_reshaped <- melt(events, id=c("group_id","date"))
data_reshaped <- data_reshaped[order(data_reshaped$group_id),] 
data_reshaped <- data_reshaped[data_reshaped$variable == "EID",] 

lda_out.topics <- as.data.frame(lda_out.topics)
data_reshaped$value <- as.integer(data_reshaped$value)
data_reshaped <- data_reshaped %>% left_join(lda_out.topics, by = c("value" = "EID"))


data_reshaped$value <- data_reshaped$V1
library(reshape)
final <- cast(data_reshaped, group_id~date, function(x) max(x), value="V1")

for (i in 1:nrow(final)){
  nums <- unique(unlist(final[i, 2:338]))
  nums[!is.finite(nums)] <- 0
  k <- length(nums)
  
  final$unique[i] <- k 
}

#Group description's topic modeling (how many unique topics are available?)
summary(final$unique)
hist(final$unique[final$unique != 0])
table(final$unique[final$unique != 0])

```



# Selecting IT/Big-Data-related Groups
```{r}
groups = read_delim("group_results.csv", delim = ",",col_names = TRUE ) 

groups %<>% filter(str_detect(groups$tags, "software") | str_detect(groups$tags, "data") | str_detect(groups$tags, "tech") | str_detect(groups$tags, "startup") | str_detect(groups$tags, "start-up") | str_detect(groups$tags, "analytics") | str_detect(groups$tags, "machine learning") | str_detect(groups$tags, "computer") | str_detect(groups$tags, "information-systems") | str_detect(groups$tags, "programming") | str_detect(groups$tags, "project-management") | str_detect(groups$category, "tech"))

groups$description <- sapply(groups$description, function(x) gsub("<.*?>", "", x))
data_groups <- groups
data_groups$date <- paste(data_groups$year,data_groups$month,data_groups$day,sep="")

myReader <- readTabular(mapping=list(content="description", id="GID"))
tm <- VCorpus(DataframeSource(data_groups), readerControl=list(reader=myReader))
tm <-tm_map(tm,content_transformer(tolower))
toSpace <- content_transformer(function(x, pattern) { return (gsub(pattern, " ", x))})
tm <- tm_map(tm, toSpace, "-")
tm <- tm_map(tm, toSpace, "'")
tm <- tm_map(tm, toSpace, "\n")
tm <- tm_map(tm, removePunctuation)
#Strip digits
tm <- tm_map(tm, removeNumbers)
#remove stopwords
tm <- tm_map(tm, removeWords, stopwords("english"))
#remove whitespace
tm <- tm_map(tm, stripWhitespace)

#custom stopwords
myStopwords <- c("nbsp", "amp", "meetup", "http", "can", "get", "will", "join", "like", "group", "event", "events", "people", "new")
tm <- tm_map(tm, removeWords, myStopwords)

#writeLines(as.character(tm[[30]]))
dtm <- DocumentTermMatrix(tm)
dtm <- removeSparseTerms(dtm, sparse=0.98)

rowTotals <- apply(dtm , 1, sum)
dtm   <- dtm[rowTotals> 0, ] 

# data("AssociatedPress", package="topicmodels")
# dtm1 <- AssociatedPress[1:10, ]

result2 <- FindTopicsNumber(
  dtm,
  topics = seq(from = 21, to = 40, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  mc.cores = 2L,
  verbose = TRUE
)

FindTopicsNumber_plot(result2)

result2


##### Topic Models for Optimum K's

burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,10001,765)
nstart <- 5
best <- TRUE
k <- 31 # number of topic categories on MeetUp.com

# lda_out <- LDA(dtm, k, method="Gibbs", control=list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))

lda_out <- LDA(dtm, k)
lda_out.topics <- as.matrix(topics(lda_out))
write.csv(lda_out.topics,file=paste("LDAstop",k,"DocsToTopics.csv"))

#top 10 terms in each topic
lda_out.terms <- as.matrix(terms(lda_out,10))
write.csv(lda_out.terms,file=paste("LDAstop",k,"TopicToTerms.csv"))

#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(lda_out@gamma)
write.csv(topicProbabilities,file=paste("LDAstop",k,"TopicProb.csv"))


data_reshaped <- melt(data_groups, id=c("group_id","date"))
data_reshaped <- data_reshaped[order(data_reshaped$group_id),] 
data_reshaped <- data_reshaped[data_reshaped$variable == "GID",] 

lda_out.topics <- as.data.frame(lda_out.topics)
lda_out.topics$GID <- rownames(lda_out.topics)
data_reshaped = data_reshaped %>% left_join(lda_out.topics, by = c("value" = "GID"))
data_reshaped$value <- data_reshaped$V1
library(reshape)
final <- cast(data_reshaped, group_id~date, value="V1")

for (i in 1:nrow(final)){
  prev = 0
  add = 0
  sub = 0
  
  seq <- unlist(final[i, 2:13])
    
  for (j in 1:length(seq)){
    if (is.na(seq[j])) next
    if (prev == seq[j] || j == 1 ) {
      prev <- seq[j]
      next
    } else if (prev < seq[j] ){
      add <- add + 1
    } else {
      sub <- sub + 1
    }
    prev <- seq[j]
  }
  
  final$add[i] <- add
  final$sub[i] <- sub
}

summary(final$add)
table(final$add)
hist(final$add)

summary(final$sub)
table(final$sub)
hist(final$sub)


```

#Term Frequency
```{r}
groups %<>% filter(str_detect(groups$category, "tech"))
tags <- toString(groups$tags)
tags <- unlist(strsplit(tags, split=", "))

tag_corpus <- Corpus(VectorSource(tags))

dtm <- DocumentTermMatrix(tag_corpus)   
freq <- colSums(as.matrix(dtm))   
length(freq)
ord <- order(-freq) 
View(freq[ord])

write.csv(freq[ord], file="tech_term_freq.csv")
hist(freq[ord])
```

